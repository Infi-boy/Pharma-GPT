{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9s5Jg7lTShdPMeab59bbw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JfveWS2zIv68"},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","tf.config.run_functions_eagerly(True)\n","df = pd.read_csv('Data/ai_data.csv', index_col = [0])\n","df_original = df.copy()\n","df = df[['seq', 'SMILE', 'InChI']]\n","df.dropna(inplace = True)\n","len(df)\n","\n","tmp = pd.DataFrame(df[['seq', 'SMILE']].agg(' '.join, axis=1).str.len()).rename(columns = {0:'length'})\n","df = df[tmp.length < 4097].copy()\n","####\n","#custom tokenization map . one can use the lib, we are using the lib\n","\n","seq_map = pd.read_csv('Data/seq_map.csv', index_col = [0])\n","smile_map = pd.read_csv('Data/smile_map.csv', index_col = [0])\n","inchi_map = pd.read_csv('Data/inchi_map.csv', index_col = [0])\n"]},{"cell_type":"code","source":["\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","# max_length = 4096\n","class CustomTokenizer:\n","    def __init__(self, vocabulary):\n","        # Create vocabulary mappings\n","        self.vocab = {word: idx for idx, word in enumerate(vocabulary)}\n","        self.vocab['pad'] = len(self.vocab)\n","        self.idx_to_word = {idx: word for word, idx in self.vocab.items()}\n","\n","        # Handle special tokens\n","        self.start_token_id = self.vocab.get('[START]')\n","        self.end_token_id = self.vocab.get('[END]')\n","        self.sep_token_id = self.vocab.get('[SEP]')\n","        self.pad_token_id = self.vocab.get('[PAD]')\n","        self.vocab_size = len(vocabulary)\n","\n","    def encode(self, input_text):\n","        # Tokenize input and output text, adding separator\n","        input_tokens = input_text.split()\n","\n","\n","        input_ids = [self.vocab.get(token, self.vocab.get('[END]')) for token in input_tokens]\n","        # Combine with start and end tokens\n","        return [self.start_token_id] + input_ids\n","\n","    def encode_test(self, input_text):\n","        # Tokenize input and output text, adding separator\n","        input_tokens = input_text\n","        input_tokens = list(input_tokens)\n","        input_ids = [self.vocab.get(token, self.vocab.get('[END]')) for token in input_tokens]\n","        # Combine with start and end tokens\n","        return input_ids\n","    def decode(self, token_ids):\n","        # Convert token IDs back to text, excluding special tokens\n","        tokens = [self.idx_to_word.get(token_id) for token_id in token_ids if token_id not in [self.start_token_id, self.end_token_id, self.sep_token_id]]\n","        return ''.join(tokens)\n","    def vocab_output_vector(self, token):\n","        # Initialize vector of zeros with size equal to vocab size\n","        output_vector = np.zeros(self.vocab_size)\n","        # Get the index of the token and set the corresponding index to 1\n","        token_id = self.vocab.get(token, self.vocab.get('[END]'))  # Default to [END] if token not found\n","        output_vector[token_id] = 1\n","        return output_vector\n","\n","#Vocabulary input, target input, right shift target input.\n","vi = list(set ( list(seq_map.seq))) + ['[PAD]','[END]']\n","vt = list(set (list(smile_map.smile)))+ ['[START]','[END]', '[PAD]']\n","\n","source = CustomTokenizer(vi)\n","target = CustomTokenizer(vt)\n"],"metadata":{"id":"zCzm4HdbJDK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LSTM, Embedding, LayerNormalization, Dropout\n","import numpy as np\n","\n","# Scaled Dot-Product Attention\n","def scaled_dot_product_attention(query, key, value, mask):\n","    matmul_qk = tf.matmul(query, key, transpose_b=True)\n","    dk = tf.cast(tf.shape(key)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    output = tf.matmul(attention_weights, value)\n","\n","    return output, attention_weights\n","\n","# Multi-Head Attention\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.depth = d_model // num_heads\n","\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, query, key, value, mask):\n","        batch_size = tf.shape(query)[0]\n","\n","        query = self.wq(query)\n","        key = self.wk(key)\n","        value = self.wv(value)\n","\n","        query = self.split_heads(query, batch_size)\n","        key = self.split_heads(key, batch_size)\n","        value = self.split_heads(value, batch_size)\n","\n","        output, attention_weights = scaled_dot_product_attention(query, key, value, mask)\n","        output = tf.transpose(output, perm=[0, 2, 1, 3])\n","        output = tf.reshape(output, (batch_size, -1, self.d_model))\n","\n","        return self.dense(output), attention_weights\n","\n","# Point-wise Feed-Forward Network\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        Dense(dff, activation='relu'),\n","        Dense(d_model)\n","    ])\n","\n","# Encoder Block\n","class EncoderBlock(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderBlock, self).__init__()\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","\n","    def call(self, x, mask, training):\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","# Decoder Block\n","class DecoderBlock(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderBlock, self).__init__()\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        self.dropout3 = Dropout(rate)\n","\n","    def call(self, x, enc_output, look_ahead_mask, padding_mask, training):\n","        attn1, _ = self.mha1(x, x, x, look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(x + attn1)\n","\n","        # Cross-attention with the encoder output\n","        attn2, _ = self.mha2(out1, enc_output, enc_output, padding_mask)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(out1 + attn2)\n","\n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        return self.layernorm3(out2 + ffn_output)\n","\n","# Encoder\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, rate=0.1):\n","        super(Encoder, self).__init__()\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.embedding = Embedding(vocab_size, d_model)\n","        # self.pos_encoding = self.positional_encoding(1000, d_model) # 1000 is the sequence length\n","        self.pos_encoding = self.positional_encoding(5000, d_model)\n","\n","        self.enc_layers = [EncoderBlock(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = Dropout(rate)\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","        return tf.cast(angle_rads[np.newaxis, ...], tf.float32)\n","\n","    def get_angles(self, position, i, d_model):\n","        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","        return position * angle_rates\n","\n","    def call(self, x, mask, training):\n","        seq_len = tf.shape(x)[1]\n","        x = self.embedding(x)\n","        x += self.pos_encoding[:, :seq_len, :]\n","        # x = self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, mask=mask, training=training)\n","\n","        return x\n","\n","# Decoder\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, rate=0.1):\n","        super(Decoder, self).__init__()\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.embedding = Embedding(vocab_size, d_model)\n","        # self.pos_encoding = self.positional_encoding(1000, d_model) # 1000 is the sequence length\n","        self.pos_encoding = self.positional_encoding(598, d_model)\n","\n","        self.dec_layers = [DecoderBlock(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = Dropout(rate)\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","        return tf.cast(angle_rads[np.newaxis, ...], tf.float32)\n","\n","    def get_angles(self, position, i, d_model):\n","        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","        return position * angle_rates\n","\n","    def call(self, x, enc_output, look_ahead_mask, padding_mask, training):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","\n","        x = self.embedding(x)\n","        x += self.pos_encoding[:, :seq_len, :]\n","        # x = self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x = self.dec_layers[i](x, enc_output=enc_output, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask, training=training)\n","\n","        return x\n","\n","# Transformer Model (Encoder-Decoder)\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, rate=0.1, source=None, target=None):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, rate)\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, rate)\n","        self.lstm_layer = LSTM(units=d_model, return_sequences=True)\n","        # self.final_layer = Dense(target_vocab_size, activation='softmax')\n","        self.final_layer = Dense(target_vocab_size)\n","        self.source = source\n","        self.target = target\n","\n","    def create_padding_mask(self, seq, padding_token):\n","        # seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","        seq = tf.cast(tf.math.equal(seq, padding_token), tf.float32)\n","        return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n","\n","    def create_look_ahead_mask(self, size):\n","        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","        return mask  # (seq_len, seq_len)\n","\n","    def create_masks(self, inp, tar):\n","        # Encoder padding mask\n","        enc_padding_mask = self.create_padding_mask(inp, self.source.pad_token_id)\n","\n","        # Decoder padding mask (same as encoder padding mask, used during cross-attention)\n","        dec_padding_mask = self.create_padding_mask(inp, self.target.pad_token_id)\n","\n","        # Look-ahead mask (for autoregressive decoding) and combining with target padding mask\n","        look_ahead_mask = self.create_look_ahead_mask(tf.shape(tar)[1])\n","        dec_target_padding_mask = self.create_padding_mask(tar, self.target.pad_token_id)\n","        combined_look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","        return enc_padding_mask, combined_look_ahead_mask, dec_padding_mask\n","\n","    def call(self,inputs, training):\n","        inp, right_shifted_tar = inputs\n","        \"\"\"\n","        Args:\n","            inp: input tensor (source sequence)\n","            right_shifted_tar: decoder input (right-shifted target sequence)\n","            training: whether it's training (boolean)\n","\n","        Returns:\n","            final_output: logits (before softmax) for the next token predictions\n","        \"\"\"\n","        # Create masks internally\n","        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, right_shifted_tar)\n","\n","        # Encoder output\n","        enc_output = self.encoder(inp, mask=enc_padding_mask, training=training)\n","\n","        # Decoder output (taking right-shifted target as input)\n","        dec_output = self.decoder(right_shifted_tar, enc_output=enc_output, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask, training=training)\n","        lstm_output = self.lstm_layer(dec_output)\n","        # Final linear layer for logits (prediction)\n","        final_output = self.final_layer(lstm_output)\n","\n","        return final_output\n"],"metadata":{"id":"AfGINC12JGP-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example input and target (toy example)\n","input_sequence = tf.constant([[1, 2, 3, 4, 0]])  # Source sequence (input)\n","target_sequence = tf.constant([[1, 5, 6, 7, 0]])  # Target sequence (actual output)\n","\n","# Right-shift the target sequence to create the decoder input\n","right_shifted_target = tf.constant([[0, 1, 5, 6, 7]])  # Right-shifted target (decoder input)\n","\n","# Model configuration\n","# input_vocab_size = source.vocab_size\n","# target_vocab_size = target.vocab_size\n","# num_layers = 2\n","# d_model = 48\n","# num_heads = 8\n","# dff = 1024\n","\n","input_vocab_size = source.vocab_size\n","target_vocab_size = target.vocab_size\n","num_layers = 1\n","d_model = 32\n","num_heads = 8\n","dff = 1024\n","## ClcC\n","\n","# input_vocab_size = source.vocab_size\n","# target_vocab_size = target.vocab_size\n","# num_layers = 4\n","# d_model = 64\n","# # d_model = 5000\n","# num_heads = 8\n","# dff = 1024\n","#performance increased again\n","\n","# input_vocab_size = source.vocab_size\n","# target_vocab_size = target.vocab_size\n","# num_layers = 3\n","# d_model = 64\n","# # d_model = 5000\n","# num_heads = 8\n","# dff = 1024\n","#increased performance\n","\n","# Instantiate the transformer model\n","# transformer = Transformer(num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size)\n","# with tf.device('/device:GPU:0'):\n","transformer = Transformer(num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, source=source, target=target)\n","\n","# Predict the output (logits) for the given input and right-shifted target\n","output_logits = transformer([input_sequence, right_shifted_target], training=False)\n","\n","# Print the output logits (logits before applying softmax)\n","# print(\"Output logits:\\n\", output_logits)\n"],"metadata":{"id":"EafPUEJFJKdN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import clear_output\n","import math\n","\n","def convert_output_to_probabilities(out):\n","  batch_size, seq_length = out.shape\n","  vocab_size = target.vocab_size  # Example vocabulary size\n","\n","  # Create a new array for one-hot encoding\n","  one_hot_encoded = np.zeros((batch_size, seq_length, vocab_size), dtype=int)\n","\n","  # Set the appropriate indices to 1\n","  one_hot_encoded[np.arange(batch_size)[:, None], np.arange(seq_length), out] = 1\n","  return one_hot_encoded\n","\n","def infer(inp):\n","  prompt_len = 100\n","  output_sequence = []\n","  rpred =  np.array([[target.start_token_id]])\n","  for i in range(0,prompt_len):\n","    input_sequence = np.expand_dims(inp[0], axis=0)  # Shape: (1, 35)\n","    predictions = transformer([input_sequence, rpred], training=False)\n","    predicted_logits = predictions[:, -1, :]\n","    predicted_token = tf.argmax(tf.nn.softmax(predicted_logits), axis=-1).numpy()[0]\n","    output_sequence.append(predicted_token)\n","    rpred = np.concatenate([rpred, np.array([[predicted_token]])], axis=-1)\n","  print(target.decode(output_sequence).split('[PAD]')[0].split('[END]')[0])\n","\n","def max_pad(inpu_data):\n","  return max([i.shape[1] for i in inpu_data])\n","\n","def pad_data(inpu_data, value=None):\n","  max_length = max_pad(inpu_data)\n","  for i in range(len(inpu_data)):\n","    inpu_data[i] = pad_sequences(\n","        inpu_data[i],\n","        maxlen = max_length,\n","        padding='post',\n","        value=value\n","        )\n","  inpu_data=np.concatenate(inpu_data)\n","  return inpu_data\n","\n","cat = 0\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","if cat == 1:\n","  transformer.compile(\n","      optimizer=optimizer,\n","      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","      metrics=['accuracy']\n","  )\n","else:\n","  transformer.compile(\n","      optimizer='adam',  # Choose an appropriate optimizer\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # Use from_logits=True if outputs are logits\n","      metrics=['accuracy']  # Optional: you can add other metrics as needed\n","  )\n","\n","\n","batch = 221170*2\n","input_data,  routput_data , output_data= [],[],[]\n","frac = len(df) / batch\n","for i in range(0,int(batch)):\n","  print(len(df) / batch)\n","  print(i*frac, (i + 1)* frac)\n","  tmp = df[int(i*frac) : int((i + 1)* frac )].copy()\n","  for j, row in tmp.iterrows():\n","    inp,rout, out = [], [], []\n","    multiple = len(row.seq) / len(row.SMILE)\n","    remainder = len(row.seq) % len(row.SMILE)\n","    if len(row.seq) > len(row.SMILE):\n","      # print(multiple, remainder,len(row.seq),len(row.SMILE))\n","      for k in range(len(row.SMILE)):\n","        inp.append(source.encode_test(row.seq))\n","        out.append([target.start_token_id] + [target.encode_test(l)[0]  for l in row.SMILE[:k+1] for _ in range(math.floor(multiple)) ])\n","        rout.append([target.start_token_id] + [target.encode_test(l)[0]  for l in row.SMILE[:k] for _ in range(math.floor(multiple)) ])\n","      k += 1\n","      inp.append(source.encode_test(row.seq))\n","      rout.append([target.start_token_id] + [target.encode_test(l)[0]  for l in row.SMILE[:k] for _ in range(math.floor(multiple)) ])\n","      out.append([target.start_token_id] + [target.encode_test(l)[0]  for l in row.SMILE[:k] for _ in range(math.floor(multiple)) ] + [target.end_token_id])\n","\n","      inp = pad_sequences(inp, padding = 'post', value=source.pad_token_id)\n","      out = pad_sequences(out, padding = 'post', value=target.pad_token_id)\n","      if cat == 1:\n","        out = convert_output_to_probabilities(out)\n","      rout = pad_sequences(rout, maxlen = len(out[-1]), padding = 'post', value=target.pad_token_id)\n","      input_data.append(inp)\n","      output_data.append(out)\n","      routput_data.append(rout)\n","\n","  input_data = pad_data(input_data, value = source.pad_token_id)\n","  output_data = pad_data(output_data, value=target.pad_token_id)\n","  routput_data = pad_data(routput_data,value=target.pad_token_id)\n","  break\n","# remove break for production level training\n","# add model.fit in the loop"],"metadata":{"id":"3UZYwRgTJQFu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device('/device:GPU:0'):\n","  transformer.fit([input_data,routput_data],output_data,epochs =100, batch_size = 32)\n","transformer.save('/content/drive/MyDrive/Ai-Projects/Sanjevni/Models/cross_pharma.keras')\n"],"metadata":{"id":"RMcyZa32JiOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import clear_output\n","\n","def remove_consecutive_duplicates(s):\n","    result = s[0]  # Start with the first character\n","    for char in s[1:]:\n","        if char != result[-1]:\n","            result += char\n","    return result\n","\n","def infer(inp):\n","  prompt_len = inp.shape[1]\n","  output_sequence = []\n","  rpred =  np.array([[target.start_token_id]])\n","  for i in range(0,prompt_len):\n","    print(i)\n","    input_sequence = np.expand_dims(inp[-1], axis=0)  # Shape: (1, 35)\n","    predictions = transformer([input_sequence, rpred], training=False)\n","    predicted_logits = predictions[:, -1, :]\n","    predicted_token = tf.argmax(tf.nn.softmax(predicted_logits), axis=-1).numpy()[0]\n","    output_sequence.append(predicted_token)\n","    rpred = np.concatenate([rpred, np.array([[predicted_token]])], axis=-1)\n","    clear_output()\n","  pred = remove_consecutive_duplicates(target.decode(output_sequence))\n","  return pred\n","pred = infer(inp)\n","print(pred)"],"metadata":{"id":"RIHn2GKjJo2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ovHx9I4GJu03"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Best of Luck, Have fun"],"metadata":{"id":"TL3hNLi-JvUt"}}]}